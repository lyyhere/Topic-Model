{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import json\n",
    "import pickle\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# import os\n",
    "# import sys\n",
    "# import operator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log, log10\n",
    "# import scipy.stats as scs\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import matplotlib.dates as mdates\n",
    "# %matplotlib inline\n",
    "# import json\n",
    "\n",
    "# model imports\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# # model evaluation imports\n",
    "# from sklearn import model_selection, preprocessing, ensemble\n",
    "# from sklearn.metrics import log_loss\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import pyLDAvis.gensim\n",
    "\n",
    " \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_df(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "            print(\"Loading picked\")\n",
    "            return pickle.load(f)\n",
    "\n",
    "def pickle_df(df, filename=\"./df.pickle\"):\n",
    "    if filename:\n",
    "        print(\"Writing to\", filename)\n",
    "        with open(filename, \"wb\") as output_file:\n",
    "                pickle.dump(df, output_file, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading picked\n"
     ]
    }
   ],
   "source": [
    "df_reviews = load_df(\"df_reviews_only.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rev_description', 'rev_publishedAt', 'rev_quickTake', 'rev_rating',\n",
       "       'rev_title', 'rev_age', 'rev_badge', 'rev_eyeColor', 'rev_location',\n",
       "       'rev_name', 'rev_skinTone', 'rev_skinType'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) \n",
    "stop = list(exclude) + stopwords.words('english')\n",
    "snowball = SnowballStemmer('english')\n",
    "lemma = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def clean(doc):\n",
    "    tokens = \" \".join(nltk.word_tokenize(doc)).lower()\n",
    "    stop_free = \" \".join([i for i in tokens.split() if i not in stop])\n",
    "    normalized = \" \".join(snowball.stem(word) for word in stop_free.split(\" \"))\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_5star = df_reviews[df_reviews.rev_rating==5].rev_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1star = df_reviews[df_reviews.rev_rating==1].rev_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_5star_clean= df_5star.sample(df_1star.shape[0]).map(clean)\n",
    "df_1star_clean= df_1star.map(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5-star\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, min_df=2, ngram_range = (3,4))#max_features=no_features, \n",
    "tfidf = tfidf_vectorizer.fit_transform(df_5star_clean)\n",
    "frequencies = sum(tfidf).toarray()[0]\n",
    "\n",
    "unranked_5 = pd.DataFrame(frequencies, index=tfidf_vectorizer.get_feature_names(), columns=['frequency'])\n",
    "ranked_5 = unranked_5.sort_values('frequency', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 1-star\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, min_df=2, ngram_range = (3,4))#max_features=no_features, \n",
    "tfidf = tfidf_vectorizer.fit_transform(df_1star_clean)\n",
    "frequencies = sum(tfidf).toarray()[0]\n",
    "\n",
    "unranked_1 = pd.DataFrame(frequencies, index=tfidf_vectorizer.get_feature_names(), columns=['frequency'])\n",
    "ranked_1 = unranked_1.sort_values('frequency', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def for_d3(text, freq):\n",
    "    return [\"\".join([word.capitalize() for word in text.split(\" \")]), int(freq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranked_5['idx'] = ranked_5.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "r5 = ranked_5.apply(lambda x: for_d3(x['idx'], x['frequency']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>goe long way</th>\n",
       "      <td>GoeLongWay</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>littl goe long</th>\n",
       "      <td>LittlGoeLong</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>littl goe long way</th>\n",
       "      <td>LittlGoeLongWay</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make skin feel</th>\n",
       "      <td>MakeSkinFeel</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leav skin feel</th>\n",
       "      <td>LeavSkinFeel</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          frequency  idx\n",
       "goe long way             GoeLongWay  109\n",
       "littl goe long         LittlGoeLong   86\n",
       "littl goe long way  LittlGoeLongWay   86\n",
       "make skin feel         MakeSkinFeel   80\n",
       "leav skin feel         LeavSkinFeel   77"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_1['idx'] = ranked_1.index\n",
    "r1 = ranked_1.apply(lambda x: for_d3(x['idx'], x['frequency']), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acn prone skin</th>\n",
       "      <td>AcnProneSkin</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realli want like</th>\n",
       "      <td>RealliWantLike</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realli want love</th>\n",
       "      <td>RealliWantLove</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want love product</th>\n",
       "      <td>WantLoveProduct</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high hope product</th>\n",
       "      <td>HighHopeProduct</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         frequency  idx\n",
       "acn prone skin        AcnProneSkin   61\n",
       "realli want like    RealliWantLike   53\n",
       "realli want love    RealliWantLove   49\n",
       "want love product  WantLoveProduct   36\n",
       "high hope product  HighHopeProduct   35"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "r5.to_csv(\"ranked_5.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1.to_csv(\"ranked_1.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
